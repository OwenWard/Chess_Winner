---
title: "Response to Reviewer Comments"
author: Adam Gee
date: today
format: 
  pdf
---


This document will create all numeric and graphical
summaries contained in the submitted response to reviewer comments.



```{r setup}
#| include: false

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.width = 7, dev = "png", fig.path = "output/",
                      fig.height = 5, dpi = 600)

library(tidyverse)
library(RcppRoll)
library(cmdstanr)
library(posterior)
library(bayesplot)
library(loo)
library(scales)
library(ggridges)
library(here)
library(ggdist)
library(viridis)
library(PlayerRatings)
library(ggrepel)
library(ggpubr)
library(rstanarm)
library(ggh4x)
library(latex2exp)
library(furrr)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


## to load some plot defaults
source(here("utils", "helper.R"))
source(here("utils", "plot_templates.R"))

all_data_path <- rep(NA, 4)
all_data_path[1] <- here("box_data/lichess1700-1900/")
all_data_path[2] <- here("box_data/lichess2000-2200/")
all_data_path[3] <- here("box_data/lichess2300-2500/")
all_data_path[4] <- here("box_data/lichessGrandmasters/")
res_data_path <- rep(NA, 4)
res_data_path[1] <- here("results_2025/lichess1700-1900/")
res_data_path[2] <- here("results_2025/lichess2000-2200/")
res_data_path[3] <- here("results_2025/lichess2300-2500/")
res_data_path[4] <- here("results_2025/lichessGrandmasters/")

```



#Associate Editor, Comment 5 - plotting RDs and volatilities
```{r}
#import data
data_path = paste0(all_data_path[4])

files <- list.files(data_path)

lichess_data <- files |> 
  map_dfr(~read_player(paste0(data_path, "/"), .x))
users <- readRDS(file = here("results_revision", "lichessGrandmasters", "users_bullet.RDS"))

small_data <- lichess_data |>
  mutate(Event = tolower(Event)) |>
  filter(Event == paste0("rated bullet game"),
         Variant == "Standard") |>
  filter(TimeControl %in% c("60+0", "180+0")) |> 
  distinct() #remove the duplicate rows if they exist

## otherwise not needed
users <- small_data |>
  group_by(Username) |>
  tally() |>
  filter(n >= 10) |>
  pull(Username)

tidy_games <- map_dfr(users, get_hist, small_data, prev_n = 1) |> 
  as_tibble() 

init_data <- tidy_games |>
  mutate(WhiteElo = as.numeric(WhiteElo),
         BlackElo = as.numeric(BlackElo),
         focal_user = ifelse(focal_white == 1, White, Black),
         elo_diff = ifelse(focal_white == 1,
                           WhiteElo - BlackElo, BlackElo - WhiteElo),
         focal_id = match(focal_user, users),
         focal_rating = ifelse(focal_white == 1, WhiteElo, BlackElo),
         opp = ifelse(focal_white == 1, Black, White),
         opp_rating = ifelse(focal_white == 1, BlackElo, WhiteElo),
         UTCDateTime = ymd_hms(paste0(UTCDate, "_", UTCTime))) |>
  dplyr::select(focal_user, focal_id, focal_white, WhiteElo, BlackElo, White, Black,
                focal_win_prop, elo_diff, focal_result, opp, opp_rating,
                focal_rating, UTCDateTime) |>
  group_by(focal_id) |>
  mutate(time_diff = UTCDateTime - lag(UTCDateTime, default = NA), #default is to ensure first game is always start of a new session
         cum_win_prob = cummean(focal_result), #the mean win probability for the focal player up to the ith (current) game 
         ave_prop = ifelse(time_diff > 300 | is.na(time_diff),  
                           0, #if games played in different session, history is their mean win prob up to the current game
                           lag(focal_win_prop) - cum_win_prob)) |> #if game played in same session, rolling mean over the past n games, removing standardization 
  filter(focal_result != 0.5) %>%
  ungroup()


#get RDs
plan(multisession, workers = 12) #in parallel - dramatically speeds it up
start = Sys.time()
init_RDs = future_map_dfr(users, get_RDs, init_data) |>
  as_tibble()
end = Sys.time()
end - start #takes 1.3 min

#RDs
RD_plot = ggplot(data = init_RDs %>% group_by(focal_user) %>% mutate(index = row_number()), mapping = aes(x = index, y = RD)) +
  geom_line() +
  scale_x_continuous(n.breaks = 3, limits = c(0, 5000)) +
  scale_y_continuous(limits = c(50, 100)) +
  labs(x = "Game Number", y = "Rating Deviation") +
  facet_wrap(~focal_user)

#save
ggsave(plot = RD_plot,
       filename = here("Paper_WriteUp", "paper_figures", "response to comments", "RDs.png"), dpi = 1000,
       height = 6, width = 8)

#volatilities
vol_plot = ggplot(data = init_RDs %>% group_by(focal_user) %>% mutate(index = row_number()), mapping = aes(x = index, y = volatility)) +
  geom_line() +
  scale_x_continuous(n.breaks = 3, limits = c(0, 5000)) +
  #scale_y_continuous(limits = c(0.04, 0.06)) +
  labs(x = "Game Number", y = "Rating Deviation") +
  facet_wrap(~focal_user)

#save
ggsave(plot = vol_plot,
       filename = here("Paper_WriteUp", "paper_figures", "response to comments", "volatilities.png"), dpi = 1000,
       height = 6, width = 8)
```



#Reviewer 2, Comment 6 - distribution of x_{ij}
```{r}
#import data
data_path = paste0(all_data_path[1], "/")

files <- list.files(data_path)
lichess_data <- files |> 
  map_dfr(~read_player(data_path, .x))

small_data <- lichess_data |>
  mutate(Event = tolower(Event)) |>
  filter(Event == paste0("rated ", time_control, " game"),
         Variant == "Standard") |>
  filter(TimeControl %in% c("60+0", "180+0")) |> 
  distinct() #remove the duplicate rows if they exist

## otherwise not needed
users <- small_data |>
  group_by(Username) |>
  tally() |>
  filter(n >= 10) |>
  pull(Username)

tidy_games <- map_dfr(users, get_hist, small_data, prev_n = n) |> 
  as_tibble() 

init_data <- tidy_games |>
  mutate(WhiteElo = as.numeric(WhiteElo),
         BlackElo = as.numeric(BlackElo),
         focal_user = ifelse(focal_white == 1, White, Black),
         elo_diff = ifelse(focal_white == 1,
                           WhiteElo - BlackElo, BlackElo - WhiteElo),
         focal_id = match(focal_user, users),
         UTCDateTime = ymd_hms(paste0(UTCDate, "_", UTCTime))) |>
  dplyr::select(focal_user, focal_id, focal_white, 
                focal_win_prop, elo_diff, focal_result,
                UTCDateTime) |>
  group_by(focal_id) |>
  mutate(time_diff = UTCDateTime - lag(UTCDateTime, default = NA), #default is to ensure first game is always start of a new session
         cum_win_prob = cummean(focal_result), #the mean win probability for the focal player up to the ith (current) game 
         ave_prop = ifelse(time_diff > 300 | is.na(time_diff),  #current way we evaluate history
                           0, 
                           lag(focal_win_prop) - cum_win_prob),
         ave_prop2 = ifelse(time_diff > 300 | is.na(time_diff), #proposed way we evaluate history
                            0.5, 
                            lag(focal_win_prop))) |> 
  filter(focal_result != 0.5) %>%
  ungroup()

#just filter for one player for illustration
init_data_plot = init_data %>% filter(focal_id == 1)

#distribution of x_ij for current way we evaluate history
curr_dist = ggplot(data = init_data_plot, mapping = aes(x = ave_prop)) +
  geom_histogram() + 
  labs(title = "Normalization", x = TeX("$\\tilde{x}_{ij}^n$"), y = "Count") + 
  scale_x_continuous(breaks = c(-0.5, -0.25, 0, 0.25, 0.5), labels = c(-0.5, -0.25, 0, 0.25, 0.5)) + 
  theme_single_y()

#save
ggsave(plot = curr_dist,
       filename = here("Paper_WriteUp", "paper_figures", "response to comments", "curr_xij.png"), dpi = 1000,
       height = 4, width = 6)

#distribution of x_ij for proposed way to evaluate history
prop_dist = ggplot(data = init_data_plot, mapping = aes(x = ave_prop2)) +
  geom_histogram() + 
  labs(title = "No Normalization", x = TeX("$\\tilde{x}_{ij}^n$"), y = "Count") + 
  scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), limits = c(-0.2, 1.2)) + 
  theme_single_y()

#save
ggsave(plot = prop_dist,
       filename = here("Paper_WriteUp", "paper_figures", "response to comments", "prop_xij.png"), dpi = 1000,
       height = 4, width = 6)
```




